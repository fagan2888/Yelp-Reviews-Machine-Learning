{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tadhw2_github.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "OAYVhyabT1mT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text as Data HW2\n",
        "### By-Vaidehi Thete (vvt221)"
      ]
    },
    {
      "metadata": {
        "id": "kJbhDaAWLGx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm(list = ls())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DC3dGhRfLLlj",
        "colab_type": "code",
        "outputId": "ae369c37-05e2-49a6-c7bd-0dc86047a9c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"dplyr\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CjfV73rCLPsn",
        "colab_type": "code",
        "outputId": "d1578ddc-2845-4938-f575-e85aaea83edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"ggplot2\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "waez-6OUMuNm",
        "colab_type": "code",
        "outputId": "2d38423a-d1bf-4b39-c4e8-c5f94f0e51c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"xtable\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0d-iK5zyM7N7",
        "colab_type": "code",
        "outputId": "4e685525-b54a-4496-8f33-32c4e8b34b2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"devtools\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YBmBYAIqM9wa",
        "colab_type": "code",
        "outputId": "fa5400f7-2adc-468c-a0cc-8e5ac57f5117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "devtools::install_github(\"quanteda/quanteda.corpora\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading GitHub repo quanteda/quanteda.corpora@master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "✔  checking for file ‘/tmp/Rtmps199Iy/remotesa633073001/quanteda-quanteda.corpora-5933cc8/DESCRIPTION’\n",
            "─  preparing ‘quanteda.corpora’:\n",
            "✔  checking DESCRIPTION meta-information\n",
            "─  checking for LF line-endings in source and make files and shell scripts\n",
            "─  checking for empty or unneeded directories\n",
            "   Removed empty directory ‘quanteda.corpora/sources’\n",
            "─  looking to see if a ‘data/datalist’ file should be added\n",
            "─  building ‘quanteda.corpora_0.87.tar.gz’ (3.4s)\n",
            "   \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cZCVaqzUNArD",
        "colab_type": "code",
        "outputId": "623293e0-07bb-4d17-9cf3-7d11796e3377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "library(ggplot2)\n",
        "library(xtable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Attaching package: ‘dplyr’\n",
            "\n",
            "The following objects are masked from ‘package:stats’:\n",
            "\n",
            "    filter, lag\n",
            "\n",
            "The following objects are masked from ‘package:base’:\n",
            "\n",
            "    intersect, setdiff, setequal, union\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kbBtDscTNQRC",
        "colab_type": "code",
        "outputId": "bfdc208a-0170-4974-9b66-02c1135eb8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"pbapply\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FJyGiGzWSdJH",
        "colab_type": "code",
        "outputId": "0a7888c9-32b6-48d7-b9f1-2067d0a914d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"quanteda\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "also installing the dependencies ‘coda’, ‘extrafontdb’, ‘Rttf2pt1’, ‘RcppEigen’, ‘statnet.common’, ‘reticulate’, ‘ISOcodes’, ‘data.table’, ‘extrafont’, ‘fastmatch’, ‘ggrepel’, ‘network’, ‘RSpectra’, ‘RcppParallel’, ‘sna’, ‘SnowballC’, ‘spacyr’, ‘stopwords’, ‘RcppArmadillo’\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mBtCL8lYRhW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "library(\"readtext\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OwXRmdK5Vm_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "install.packages(\"caret\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e1Z0ycXpVp_2",
        "colab_type": "code",
        "outputId": "4e0b7597-9013-483e-8356-aaa6d36b59f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "library(\"caret\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading required package: lattice\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "POxcpg2jWoo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "library(readtext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uq6oL__6ahlY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "library(quanteda)\n",
        "library(quanteda.corpora)\n",
        "\n",
        "library(dplyr)\n",
        "library(e1071)\n",
        "library(randomForest)\n",
        "library(kernlab)\n",
        "library(caret)\n",
        "library(quanteda)\n",
        "library(stringr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cVFSjytiAV8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1"
      ]
    },
    {
      "metadata": {
        "id": "si4fQHSJ7nyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. We would like you to perform some Naive Bayes classification by hand (that is, you may\n",
        "use math functions or DFM-creating functions, but not any built-in naive Bayes functions).\n",
        "Make sure to show your work!**"
      ]
    },
    {
      "metadata": {
        "id": "iKMpNZ_r72Cg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) Imagine a situation in which you receive emails from the two main U.S. parties in anticipation\n",
        "of the 2020 election. The contents of those emails after all relevant preprocessing\n",
        "are displayed in Table 1. Using the standard Naive Bayes classifier without smoothing,\n",
        "estimate for each party the posterior probability (or rather, the prior multiplied by\n",
        "the likelihood) that the following email was sent by the respective party: “immigration\n",
        "voter aliens help economy”. Report these estimates. Based on these results, which party\n",
        "would you predict sent the mystery email? Explain whether you trust your findings and\n",
        "why.**"
      ]
    },
    {
      "metadata": {
        "id": "uv65w5yK5HFW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Develop a  corpus for democrats and republic emails**"
      ]
    },
    {
      "metadata": {
        "id": "_tijaxz06eNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "republican_emails <- c(\"immigration aliens wall emergency country\",\n",
        "                       \"voter economy president growth security\",\n",
        "                       \"healthcare cost socialism unfair help\")\n",
        "                       \n",
        "democratic_emails <- c(\"immigration country diversity help security\",\n",
        "                       \"healthcare universal preconditions unfair help\", \"economy inequality opportunity voter help\",\n",
        "                       \"abortion choice right women help\"\n",
        "                       )                       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MMD8pbC65OC3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Generate a dfm for democratic and republican emails**"
      ]
    },
    {
      "metadata": {
        "id": "1L569YGn6k6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "repub_dfm <- dfm(republican_emails)\n",
        "demo_dfm <- dfm(democratic_emails)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LffUd4g05dF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Create a likelihood for ords in democrat and republican emails**\n",
        "\n",
        "\n",
        "\n",
        " **Pr(tk |c) is the fraction of tokens in documents from class c that are t.**"
      ]
    },
    {
      "metadata": {
        "id": "_r1WaJAkacG8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sum perform columnise sum to obtain count of a given word diveided by the total number of words\n",
        "\n",
        "repub_likelihood <- colSums(repub_dfm) / sum(repub_dfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwXBOUG3U5Kx",
        "colab_type": "code",
        "outputId": "b3f8aa83-aff6-4cf1-d9e5-5f4f4664e17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "cell_type": "code",
      "source": [
        "repub_likelihood"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "immigration      aliens        wall   emergency     country       voter \n",
              " 0.06666667  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667 \n",
              "    economy   president      growth    security  healthcare        cost \n",
              " 0.06666667  0.06666667  0.06666667  0.06666667  0.06666667  0.06666667 \n",
              "  socialism      unfair        help \n",
              " 0.06666667  0.06666667  0.06666667 "
            ],
            "text/latex": "\\begin{description*}\n\\item[immigration] 0.0666666666666667\n\\item[aliens] 0.0666666666666667\n\\item[wall] 0.0666666666666667\n\\item[emergency] 0.0666666666666667\n\\item[country] 0.0666666666666667\n\\item[voter] 0.0666666666666667\n\\item[economy] 0.0666666666666667\n\\item[president] 0.0666666666666667\n\\item[growth] 0.0666666666666667\n\\item[security] 0.0666666666666667\n\\item[healthcare] 0.0666666666666667\n\\item[cost] 0.0666666666666667\n\\item[socialism] 0.0666666666666667\n\\item[unfair] 0.0666666666666667\n\\item[help] 0.0666666666666667\n\\end{description*}\n",
            "text/markdown": "immigration\n:   0.0666666666666667aliens\n:   0.0666666666666667wall\n:   0.0666666666666667emergency\n:   0.0666666666666667country\n:   0.0666666666666667voter\n:   0.0666666666666667economy\n:   0.0666666666666667president\n:   0.0666666666666667growth\n:   0.0666666666666667security\n:   0.0666666666666667healthcare\n:   0.0666666666666667cost\n:   0.0666666666666667socialism\n:   0.0666666666666667unfair\n:   0.0666666666666667help\n:   0.0666666666666667\n\n",
            "text/html": [
              "<dl class=dl-horizontal>\n",
              "\t<dt>immigration</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>aliens</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>wall</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>emergency</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>country</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>voter</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>economy</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>president</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>growth</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>security</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>healthcare</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>cost</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>socialism</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>unfair</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "\t<dt>help</dt>\n",
              "\t\t<dd>0.0666666666666667</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MiVuzDbMbL36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "demo_likelihood <- colSums(demo_dfm) / sum(demo_dfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHC7aIr7U8Ob",
        "colab_type": "code",
        "outputId": "2cfd043b-4a7b-4cd4-a16e-a296852df0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "cell_type": "code",
      "source": [
        "demo_likelihood"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  immigration       country     diversity          help      security \n",
              "         0.05          0.05          0.05          0.20          0.05 \n",
              "   healthcare     universal preconditions        unfair       economy \n",
              "         0.05          0.05          0.05          0.05          0.05 \n",
              "   inequality   opportunity         voter      abortion        choice \n",
              "         0.05          0.05          0.05          0.05          0.05 \n",
              "        right         women \n",
              "         0.05          0.05 "
            ],
            "text/latex": "\\begin{description*}\n\\item[immigration] 0.05\n\\item[country] 0.05\n\\item[diversity] 0.05\n\\item[help] 0.2\n\\item[security] 0.05\n\\item[healthcare] 0.05\n\\item[universal] 0.05\n\\item[preconditions] 0.05\n\\item[unfair] 0.05\n\\item[economy] 0.05\n\\item[inequality] 0.05\n\\item[opportunity] 0.05\n\\item[voter] 0.05\n\\item[abortion] 0.05\n\\item[choice] 0.05\n\\item[right] 0.05\n\\item[women] 0.05\n\\end{description*}\n",
            "text/markdown": "immigration\n:   0.05country\n:   0.05diversity\n:   0.05help\n:   0.2security\n:   0.05healthcare\n:   0.05universal\n:   0.05preconditions\n:   0.05unfair\n:   0.05economy\n:   0.05inequality\n:   0.05opportunity\n:   0.05voter\n:   0.05abortion\n:   0.05choice\n:   0.05right\n:   0.05women\n:   0.05\n\n",
            "text/html": [
              "<dl class=dl-horizontal>\n",
              "\t<dt>immigration</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>country</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>diversity</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>help</dt>\n",
              "\t\t<dd>0.2</dd>\n",
              "\t<dt>security</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>healthcare</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>universal</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>preconditions</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>unfair</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>economy</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>inequality</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>opportunity</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>voter</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>abortion</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>choice</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>right</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "\t<dt>women</dt>\n",
              "\t\t<dd>0.05</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "j8o3W-iq6XBg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. Initializing the prior probabilities based on the number of emails belonging to each class**"
      ]
    },
    {
      "metadata": {
        "id": "YHURHiTs6l57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prior_repub <- 3/7\n",
        "prior_democrat <- 4/7\n",
        "\n",
        "demo_posterior_prob <- 1.0\n",
        "repub_posterior_prob <- 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Le_rrcx6j-a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**5. Peform Naive Bayes computation by iterating through each word in the test sentence by computing the overall likelihood (if the term is already present in the vocabulary of the classes) and then multiplying it with the prior to obtain the posterior probability**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4ed5ad49-7c07-442b-bc97-c7d9b0f0b04a",
        "id": "AkUiOIrygp0S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "cell_type": "code",
      "source": [
        "repub_likehood_total <- 1.0\n",
        "demo_likehood_total <- 1.0\n",
        "for (word in list(\"immigration\",\"aliens\",\"voter\",\"aliens\",\"help\",\"economy\")) {\n",
        "  \n",
        "  #calculate posterior probability for republicans and democrats:\n",
        " \n",
        "  \n",
        "  \n",
        "  if (word %in% as.list(featnames(repub_dfm))) {\n",
        "  \n",
        "  repub_likehood_total = repub_likehood_total * as.matrix(repub_likelihood[word])[1]\n",
        "    \n",
        "  }\n",
        "  \n",
        "  else {\n",
        "  \n",
        "  next\n",
        "  }\n",
        "  \n",
        "  \n",
        "  if (word %in% as.list(featnames(demo_dfm))) {\n",
        "  demo_likehood_total = demo_likehood_total * as.matrix(demo_likelihood[word])[1]\n",
        "    \n",
        "  }\n",
        "  \n",
        "  else {\n",
        "  \n",
        "  next\n",
        "  }\n",
        "  \n",
        "  \n",
        "}\n",
        "demo_posterior_prob <- demo_likehood_total * prior_democrat\n",
        "repub_posterior_prob <- repub_likehood_total * prior_repub\n",
        "print(\"democrat posterior probability\")\n",
        "print(demo_posterior_prob)\n",
        "print(\"republican posterior probability\")\n",
        "print(repub_posterior_prob)\n",
        "print(\"Classification Output\")\n",
        "if(demo_posterior_prob > repub_posterior_prob) {\n",
        "  print(\"Democrat\")\n",
        "}else {\n",
        "  \n",
        "  print(\"Republic\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] \"democrat posterior probability\"\n",
            "[1] 1.428571e-05\n",
            "[1] \"republican posterior probability\"\n",
            "[1] 3.762493e-08\n",
            "[1] \"Classification Output\"\n",
            "[1] \"Democrat\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JgKTmtDH7N4G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Report these estimates. Based on these results, which party\n",
        "would you predict sent the mystery email? Explain whether you trust your findings and\n",
        "why.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Answer:  Based on the estimates computed it appears that the email was sent by a democrat.This is because the features in the test sentence are more likely to appear in the democrat email. **"
      ]
    },
    {
      "metadata": {
        "id": "nCNB4kV379c6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(b) Now impose Laplace smoothing on the problem and re-estimate each party’s respective\n",
        "posterior probability. Report your findings. Based on these new results, which party\n",
        "would you predict sent the mystery email? Beyond computational reasons (i.e. avoiding\n",
        "log(0)’s), can you think of any theoretical reason why smoothing might make sense (hint:\n",
        "the above data is but a sample of each party’s shared language)**\n",
        "\n",
        "\n",
        "\n",
        "**Answer: In Naive Bayes classifier, the products of probabilities of the features is evaluated during the training of the model and we clearly don't want it to evaluate to zero. So to get rid of this, we have to assign some non-zero probabilities to the words(features) which do not occur in the particular training dataset. This is what Laplace smoothing does.**"
      ]
    },
    {
      "metadata": {
        "id": "-e99ZeuPkhFC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Laplace smoothing, equivalent to a uniform prior on term (each term\n",
        "occurs once for each class)\n",
        "\n",
        "So may want to add one to each count:P\n",
        "Tct+1\n",
        "t\n",
        "0∈V\n",
        "(Tct0+1)\n",
        "to avoid wiping out\n",
        "the products "
      ]
    },
    {
      "metadata": {
        "id": "xm6i8VhB8JV2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Construct dfm for democrat and republican emails**"
      ]
    },
    {
      "metadata": {
        "id": "k2ttvl82pYby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dfm_laplace_repub <- dfm(republican_emails)\n",
        "dfm_laplace_demo <- dfm(democratic_emails)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QpbfjVyn8e8O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Compute the likelihood of each token after enabling Laplace Smoothing after adding one to total count of each word . And adding the length of vocabulary to the total count pf words in the corpus of each class**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So may want to add one to each count:P\n",
        "Tct+1\n",
        "t\n",
        "0∈V\n",
        "(Tct0+1)\n",
        "to avoid wiping out\n",
        "the products (or causing problems for taking logs). Equivalent to\n",
        "adding size of the vocabulary to the counts within the class"
      ]
    },
    {
      "metadata": {
        "id": "1lpOkddQBC0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "demo_likelihood <- (colSums(dfm_laplace_demo) + 1) / (sum(dfm_laplace_demo) + length(featnames(dfm_laplace_demo)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFmMKBNsuT-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "repub_likelihood <- (colSums(dfm_laplace_repub) + 1) / (sum(dfm_laplace_repub) + length(featnames(dfm_laplace_repub)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PSB6Kc5_umZd",
        "colab_type": "code",
        "outputId": "ea1b7486-ffd6-4679-94e5-874500134cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "cell_type": "code",
      "source": [
        "colSums(dfm_laplacian_repub) + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "immigration      aliens        wall   emergency     country       voter \n",
              "          2           2           2           2           2           2 \n",
              "    economy   president      growth    security  healthcare        cost \n",
              "          2           2           2           2           2           2 \n",
              "  socialism      unfair        help \n",
              "          2           2           2 "
            ],
            "text/latex": "\\begin{description*}\n\\item[immigration] 2\n\\item[aliens] 2\n\\item[wall] 2\n\\item[emergency] 2\n\\item[country] 2\n\\item[voter] 2\n\\item[economy] 2\n\\item[president] 2\n\\item[growth] 2\n\\item[security] 2\n\\item[healthcare] 2\n\\item[cost] 2\n\\item[socialism] 2\n\\item[unfair] 2\n\\item[help] 2\n\\end{description*}\n",
            "text/markdown": "immigration\n:   2aliens\n:   2wall\n:   2emergency\n:   2country\n:   2voter\n:   2economy\n:   2president\n:   2growth\n:   2security\n:   2healthcare\n:   2cost\n:   2socialism\n:   2unfair\n:   2help\n:   2\n\n",
            "text/html": [
              "<dl class=dl-horizontal>\n",
              "\t<dt>immigration</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>aliens</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>wall</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>emergency</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>country</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>voter</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>economy</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>president</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>growth</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>security</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>healthcare</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>cost</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>socialism</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>unfair</dt>\n",
              "\t\t<dd>2</dd>\n",
              "\t<dt>help</dt>\n",
              "\t\t<dd>2</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NA4ETNICt0YW",
        "colab_type": "code",
        "outputId": "2973bfd1-78f0-4158-e171-185af79eadf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "cell_type": "code",
      "source": [
        "repub_likehood_total <- 1.0\n",
        "demo_likehood_total <- 1.0\n",
        "\n",
        "\n",
        "demo_posterior_prob <- 1.0\n",
        "repub_posterior_prob <- 1.0\n",
        "for (word in list(\"immigration\",\"aliens\",\"voter\",\"aliens\",\"help\",\"economy\")) {\n",
        "  \n",
        "  #calculate posterior probability for republicans and democrats:\n",
        " \n",
        "  \n",
        "  \n",
        "  if (word %in% as.list(featnames(dfm_laplace_repub))) {\n",
        "  \n",
        "  repub_likehood_total = repub_likehood_total * 1 * as.matrix(repub_likelihood[word])[1]\n",
        "    \n",
        "  }\n",
        "  \n",
        "  else {\n",
        "  \n",
        "  repub_likehood_total = repub_likehood_total * 1 / (length(featnames(dfm_laplace_repub)) + sum(dfm_laplace_repub))\n",
        "  }\n",
        "  \n",
        "  \n",
        "  if (word %in% as.list(featnames(dfm_laplace_demo))) {\n",
        "  demo_likehood_total = demo_likehood_total * as.matrix(demo_likelihood[word])[1]\n",
        "    \n",
        "  }\n",
        "  \n",
        "  else {\n",
        "  \n",
        "  demo_likehood_total = demo_likehood_total *( 1 / (length(featnames(dfm_laplace_demo))*2) + sum(dfm_laplace_demo))\n",
        "  }\n",
        "  \n",
        "  \n",
        "}\n",
        "demo_posterior_prob <- demo_likehood_total * prior_democrat\n",
        "repub_posterior_prob <- repub_likehood_total * prior_repub\n",
        "print(\"Democrat Posterior Probability\")\n",
        "print(demo_posterior_prob)\n",
        "print(\"Republican Posterior Probability\")\n",
        "print(repub_posterior_prob)\n",
        "print(\"Classification Output\")\n",
        "if(demo_posterior_prob > repub_posterior_prob) {\n",
        "  print(\"Democrat\")\n",
        "}else {\n",
        "  \n",
        "  print(\"Republic\")\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] \"Democrat Posterior Probability\"\n",
            "[1] 0.004892732\n",
            "[1] \"Republican Posterior Probability\"\n",
            "[1] 3.762493e-08\n",
            "[1] \"Classification Output\"\n",
            "[1] \"Democrat\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Agukk_qzAOOY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2\n",
        "\n",
        "**For this exercise you will use a database of Yelp reviews gathered for a Kaggle challenge\n",
        "(source). Each user left a star rating of 1-5 along with a written review. You’ll be asked to\n",
        "use some of the supervised learning techniques we’ve discussed in class to analyze these texts.\n",
        "Download the most recent version from the course GitHub. The data are available in the file\n",
        "“yelp .csv”.\n",
        "Before we get started, be sure to actually read a few of the reviews, to get a feel for the language used, and any potential imperfections in the text created during the scraping process.\n",
        "For each task (3) through (6), begin with the raw version of the text, and briefly\n",
        "explain which pre-processing steps are appropriate for that particular task.**"
      ]
    },
    {
      "metadata": {
        "id": "c4yrZUxY2J-b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q2. Before we apply any classification algorithms to the Yelp reviews, we will need a general\n",
        "classifier that tells us whether the review was positive or negative—also referred to as the\n",
        "“actual score.”**"
      ]
    },
    {
      "metadata": {
        "id": "_Puz2qXDAjKw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Read in the yelp.csv file**"
      ]
    },
    {
      "metadata": {
        "id": "YW1iPSCLZuUx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_reviews <- read.csv(\"yelp.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udYlfk4l2X-W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) Divide the reviews at the empirical median score and assign each review a label as\n",
        "being “positive”—if the user score was greater than the empirical median score—or\n",
        "“negative”—if the review is less than or equal to the empirical median (you can use “1”\n",
        "and “0” as labels if you prefer, just be consistent as you do the exercises below).**"
      ]
    },
    {
      "metadata": {
        "id": "vn_cCONaAqXM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.The empirical median of the stars obtained herre is 4 stars**"
      ]
    },
    {
      "metadata": {
        "id": "mU3cDQy4eQuF",
        "colab_type": "code",
        "outputId": "bc04d42b-93ec-46ec-8eb6-4998e17e1979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "median(yelp_reviews$stars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 4"
            ],
            "text/latex": "4",
            "text/markdown": "4",
            "text/html": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2LKOF57QCDwR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.assign each review a label as being “positive”—if the user score was greater than the empirical median score—or “negative”—if the review is less than or equal to the empirical median**"
      ]
    },
    {
      "metadata": {
        "id": "LAdKEuMCfJDG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_reviews$sentiment <- ifelse(yelp_reviews$stars>median(yelp_reviews$stars),\"Positive\",\"Negative\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LLi3fNNs2gBT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(b) For some tasks, we will need “anchor” texts at the extreme of the distribution. Create\n",
        "a character variable (name it “anchor”) that has value “positive” if the user star rating\n",
        "given to a review is equal to 5, “neutral” if the user rating is less than 5 but greater\n",
        "than 1 and finally “negative” if the user rating is equal to 1. Report the proportion of\n",
        "reviews that are anchor positive, neutral and negative.**"
      ]
    },
    {
      "metadata": {
        "id": "n7c-9r5xhb2f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_reviews$anchor <- NA\n",
        "yelp_reviews$anchor[yelp_reviews$stars == 5] <- \"Positive\"\n",
        "yelp_reviews$anchor[(yelp_reviews$stars < 5) &(yelp_reviews$stars > 1)] <- \"Neutral\"\n",
        "yelp_reviews$anchor[yelp_reviews$stars == 1] <- \"Negative\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qfEUf0krCZ1y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.Report the proportion of\n",
        "reviews that are anchor positive, neutral and negative**"
      ]
    },
    {
      "metadata": {
        "id": "5aafRPQQCcYE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**a. Proportion of anchor positive texts**"
      ]
    },
    {
      "metadata": {
        "id": "sAxN8OHfgg_0",
        "colab_type": "code",
        "outputId": "4a487a13-c2b5-4e61-f9b1-f192ecde33b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "nrow(yelp_reviews[yelp_reviews$anchor == 'Positive',]) / nrow(yelp_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.3337"
            ],
            "text/latex": "0.3337",
            "text/markdown": "0.3337",
            "text/html": [
              "0.3337"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "QI7RBenkCgkG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**b. Proportion of anchor negative texts.**"
      ]
    },
    {
      "metadata": {
        "id": "VupBYJhYnjFz",
        "colab_type": "code",
        "outputId": "a829fba6-6677-4e66-e2f8-3b5c9f0eac0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "nrow(yelp_reviews[yelp_reviews$anchor == 'Negative',]) / nrow(yelp_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.0749"
            ],
            "text/latex": "0.0749",
            "text/markdown": "0.0749",
            "text/html": [
              "0.0749"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4oxV2_wZCmIt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**c. Proportion of anchor neutral texts.**"
      ]
    },
    {
      "metadata": {
        "id": "wy_QTL3VmXAq",
        "colab_type": "code",
        "outputId": "02bb15ff-ffc8-4ec5-b5aa-d45853cfd890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "nrow(yelp_reviews[yelp_reviews$anchor == 'Neutral',]) / nrow(yelp_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.5914"
            ],
            "text/latex": "0.5914",
            "text/markdown": "0.5914",
            "text/html": [
              "0.5914"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UR3WRyL723o4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. The first method we’ll use to classify reviews as being positive or negative will be dictionary\n",
        "based. To do so, you will use the dictionaries of positive and negative words discussed in Hu\n",
        "2\n",
        "& Liu (2004)—available on GitHub. You must use the dictionaries provided and may not use\n",
        "any substitutes from R packages**"
      ]
    },
    {
      "metadata": {
        "id": "APet9nVeCwDH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Steps:\n",
        "\n",
        "1. Load the list of positive and negative words from the word lists provided"
      ]
    },
    {
      "metadata": {
        "id": "AHaq9ZCepwcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "positive_words <- scan(\"positive-words.txt\", what=\"\", sep=\"\\n\")\n",
        "negative_words <- scan(\"negative-words.txt\", what=\"\", sep=\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdZ3FN0lqqwF",
        "colab_type": "code",
        "outputId": "a89d5efe-79dd-4521-d038-31cc336d1f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "positive_words[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"a+\"        \"abound\"    \"abounds\"   \"abundance\" \"abundant\" "
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'a+'\n\\item 'abound'\n\\item 'abounds'\n\\item 'abundance'\n\\item 'abundant'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'a+'\n2. 'abound'\n3. 'abounds'\n4. 'abundance'\n5. 'abundant'\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>'a+'</li>\n",
              "\t<li>'abound'</li>\n",
              "\t<li>'abounds'</li>\n",
              "\t<li>'abundance'</li>\n",
              "\t<li>'abundant'</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aWW5HoaBsj5x",
        "colab_type": "code",
        "outputId": "1f4abe3a-e360-47c4-938a-db1a68bd4bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "negative_words[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"2-faced\"    \"2-faces\"    \"abnormal\"   \"abolish\"    \"abominable\""
            ],
            "text/latex": "\\begin{enumerate*}\n\\item '2-faced'\n\\item '2-faces'\n\\item 'abnormal'\n\\item 'abolish'\n\\item 'abominable'\n\\end{enumerate*}\n",
            "text/markdown": "1. '2-faced'\n2. '2-faces'\n3. 'abnormal'\n4. 'abolish'\n5. 'abominable'\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>'2-faced'</li>\n",
              "\t<li>'2-faces'</li>\n",
              "\t<li>'abnormal'</li>\n",
              "\t<li>'abolish'</li>\n",
              "\t<li>'abominable'</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "quLx_tkP2_AZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) First, generate a sentiment score for each review based on the number of positive words\n",
        "minus the number of negative words. Then, create a vector of dichotomous variables,\n",
        "of equal length to the number of reviews, in which texts that have a positive sentiment\n",
        "score are labeled “positive,” while those with a negative score are labeled “negative”; if\n",
        "any of them have a sentiment score of 0, score them as positive. Report the percent of\n",
        "reviews in each category, and discuss the results.**"
      ]
    },
    {
      "metadata": {
        "id": "nRQZkHMcC_SG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Step:\n",
        "\n",
        "1. Create a dfm for the reviews, one dfm consisting of features based on the positive-words.txt and the other dfm of the yelp revies is based on the features found in the negative-words.txt"
      ]
    },
    {
      "metadata": {
        "id": "YD8bOACeadV7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Escape special characters in the negative word list**"
      ]
    },
    {
      "metadata": {
        "id": "bNkGwh04YrRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "quotemeta <- function(string) {\n",
        "  #str_replace_all(string, \"(\\\\W)\", \"\\\\\\\\\\\\1\")\n",
        "  string = gsub(\"([\\\\])\",\"\", string)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCrX_FN-Ys_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "negative_escaped <- quotemeta(negative_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9B1ddyl5MKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_dfm_pos <- dfm(as.character(yelp_reviews$text),select = positive_words)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAu7mBHwYXjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_dfm_neg <- dfm(as.character(yelp_reviews$text),select = negative_escaped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "EtYc7W9hDlaH"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Step:\n",
        "\n",
        "2. Calculate the row sum of each dfm to obtain the frequency of the total number of postitive and negative word features from the two lists.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JpsJ20B76V4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "overall_positive_score <- rowSums(yelp_dfm_pos)\n",
        "overall_negative_score <- rowSums(yelp_dfm_neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6787z_XbD9He"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Step:\n",
        "\n",
        "3. Take the difference of the postive and the negative word sums to obtain the overall sentiment score for each document and add it as a column to the yelp_reviews table."
      ]
    },
    {
      "metadata": {
        "id": "dWdAgxwk7Bm-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "overall_sentiment_score <- (overall_positive_score - overall_negative_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZwqgMRq8Qj9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_reviews$overall_sentiment_score <- overall_sentiment_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "v06lg3vTEXsv"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Step:\n",
        "\n",
        "4. Create a vector of dichotomous variables,\n",
        "of equal length to the number of reviews, in which texts that have a positive sentiment\n",
        "score are labeled “positive,” while those with a negative score are labeled “negative”; if\n",
        "any of them have a sentiment score of 0, score them as positive."
      ]
    },
    {
      "metadata": {
        "id": "d_0lYuzD8XsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_reviews$overall_sentiment_categorical[yelp_reviews$overall_sentiment_score >=0] <- \"Positive\"\n",
        "yelp_reviews$overall_sentiment_categorical[yelp_reviews$overall_sentiment_score <0] <- \"Negative\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X9RtZW_-Eq1G"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Step:\n",
        "\n",
        "5.  Report the percent of\n",
        "reviews in each category, and discuss the results."
      ]
    },
    {
      "metadata": {
        "id": "p6Es-zQk9JxE",
        "colab_type": "code",
        "outputId": "5cc03a34-e8ef-42ee-8891-7266b396b562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "nrow(yelp_reviews[yelp_reviews$overall_sentiment_categorical == \"Positive\",]) / nrow(yelp_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.9041"
            ],
            "text/latex": "0.9041",
            "text/markdown": "0.9041",
            "text/html": [
              "0.9041"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hBiclh-b9WmJ",
        "colab_type": "code",
        "outputId": "acb7feab-e02b-44f5-dcfc-c6b41cfc995f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "nrow(yelp_reviews[yelp_reviews$overall_sentiment_categorical == \"Negative\",]) / nrow(yelp_reviews)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 0.0959"
            ],
            "text/latex": "0.0959",
            "text/markdown": "0.0959",
            "text/html": [
              "0.0959"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5VOitK5kExJ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Discussion:\n",
        "Based on the proportion of the reviews classified based on the  Hu & Liu approach it appears that most of the reviews in the yelp data set is positive and the negative texts are relatively lesser in comparision."
      ]
    },
    {
      "metadata": {
        "id": "uenoZUFS7Uqc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(b) Create a histogram to visualize the distribution of the continuous sentiment measure.\n",
        "Your answer should be a graph.**"
      ]
    },
    {
      "metadata": {
        "id": "VeGuz2vz7I4y",
        "colab_type": "code",
        "outputId": "44a3933f-a521-4fa4-e1aa-768e515ff0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "cell_type": "code",
      "source": [
        "hist(overall_sentiment_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nDNt5Dz24mbYAAAAASUVORK5CYII=",
            "text/plain": [
              "Plot with title “Histogram of overall_sentiment_score”"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rUHngvuqFPnA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "The histogram of the continous sentiment score that most of the scores are in the range 0-5 and the positive scores have a higher frequency than the reviews which has a negative score as echoed by the proportions calculated in part 3(a)."
      ]
    },
    {
      "metadata": {
        "id": "3u2biYBb9_rR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(c) Evaluate the performance of your model at identifying positive or negative reviews by\n",
        "creating a confusion matrix with the positive and negative values assigned by the sentiment\n",
        "score (created in 3(a)) on the vertical axis and the binary “true” classifications\n",
        "(created in 2(a)) on the horizontal axis. Use this confusion matrix to compute the accuracy,\n",
        "precision, recall and F1 score of the sentiment classifier. Report these findings\n",
        "along with the confusion matrix. In terms of accuracy, how would you evaluate the\n",
        "performance of this classifier? (Hint: is there a baseline we can compare it to?)**"
      ]
    },
    {
      "metadata": {
        "id": "kkwJ8itzF12C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.  Creating a confusion matrix with the positive and negative values assigned by the sentiment score (created in 3(a)) on the vertical axis and the binary “true” classifications (created in 2(a)) on the horizontal axis.**"
      ]
    },
    {
      "metadata": {
        "id": "_nvlJXx4-DJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cmat_sentiment_classify <- table(yelp_reviews$sentiment, yelp_reviews$overall_sentiment_categorical)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o425oViZGh8j",
        "colab_type": "code",
        "outputId": "b62b806a-ea64-4041-a94d-91db446b24ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "print(cmat_sentiment_classify)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          \n",
            "           Negative Positive\n",
            "  Negative      867     5796\n",
            "  Positive       92     3245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hpS9OlgGF9ZH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Compute the accuracy, precision, recall and F1 score of the sentiment classifier**"
      ]
    },
    {
      "metadata": {
        "id": "ntiYCn31-rvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_acc_sm <- sum(diag(cmat_sentiment_classify))/sum(cmat_sentiment_classify) # accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "nb_recall_sm <- cmat_sentiment_classify[2,2]/sum(cmat_sentiment_classify[2,]) # recall = TP / (TP + FN)\n",
        "nb_precision_sm <- cmat_sentiment_classify[2,2]/sum(cmat_sentiment_classify[,2]) # precision = TP / (TP + FP)\n",
        "nb_f1_sm <- 2*(nb_recall_sm*nb_precision_sm)/(nb_recall_sm + nb_precision_sm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jKBrRvMHABby",
        "colab_type": "code",
        "outputId": "e597a512-a9ca-4851-9504-31101ddd9df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "cat(\n",
        " \n",
        "  \"Accuracy:\",  nb_acc_sm, \"\\n\",\n",
        "  \"Recall:\",  nb_recall_sm, \"\\n\",\n",
        "  \"Precision:\",  nb_precision_sm, \"\\n\",\n",
        "  \"F1-score:\", nb_f1_sm\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4112 \n",
            " Recall: 0.9724303 \n",
            " Precision: 0.3589205 \n",
            " F1-score: 0.5243173"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RtvhucHnGE5A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3.  In terms of accuracy, how would you evaluate the performance of this classifier?**\n",
        "\n",
        "**Answer:**\n",
        "In terms of accuracy, the classifier has an accuracy of 41% which means we are better of guessing these reviews randomly. It performs poorly."
      ]
    },
    {
      "metadata": {
        "id": "kHibUuXvAO3m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(d) Use the non-anchor texts for the following task as we will be comparing the result with\n",
        "that obtained using wordscores. Use the predicted sentiment score to rank the reviews,\n",
        "where 1 is the most positive review and N is the most negative. Do the same using the\n",
        "actual sentiment score (the original star rating). Compute the sum of all of the absolute\n",
        "differences between the predicted rank and the actual rank of each review (see RankSum\n",
        "represented in Equation 1). Report your findings.\n",
        "RankSum = X\n",
        "N\n",
        "i=1\n",
        "|PredictedRanki − TrueRanki\n",
        "|**"
      ]
    },
    {
      "metadata": {
        "id": "WLGIrN-PA-6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Explanation\n",
        "By non-anchor texts, I have assumed texts which have the \"neutral\" anchor.\n",
        "\n",
        "1. Using the continuous value of the sentiment score calculated in part 2(a), the reviews are ranked in decreasing order of positivity (PredictedRank Calculation)\n",
        "\n",
        "2. We also derive the actual rank based on the original star rating (TrueRank Calculation)\n",
        "\n",
        "\n",
        "3. Calculate |2 -1|\n",
        "\n",
        "4. sum 3"
      ]
    },
    {
      "metadata": {
        "id": "73qRKAcS-_tA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "non_anchor_texts <- yelp_reviews[yelp_reviews$anchor == \"Neutral\",]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R567FbrkG4zu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Using the continuous value of the sentiment score calculated in part 2(a), the reviews are ranked in decreasing order of positivity (PredictedRank Calculation)**\n",
        "\n",
        "**2. We also derive the actual rank based on the original star rating (TrueRank Calculation)**"
      ]
    },
    {
      "metadata": {
        "id": "Nw3GCo3pD8AC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "non_anchor_texts$predicted_rank <- rank(-non_anchor_texts$overall_sentiment_score)\n",
        "non_anchor_texts$true_rank <- rank(-non_anchor_texts$stars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdBQa4p6F4Df",
        "colab_type": "code",
        "outputId": "49fcb297-a460-45e2-d661-5bf21dacf2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "non_anchor_texts %>% select(predicted_rank, true_rank) %>% head(10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   predicted_rank true_rank\n",
              "3  4220.5         1763.5   \n",
              "6   497.0         1763.5   \n",
              "8  3621.0         1763.5   \n",
              "9  2474.0         1763.5   \n",
              "14  979.0         1763.5   \n",
              "15  497.0         1763.5   \n",
              "16 5800.5         5451.0   \n",
              "17 3621.0         4257.0   \n",
              "19 1980.0         4257.0   \n",
              "20 3031.0         1763.5   "
            ],
            "text/latex": "\\begin{tabular}{r|ll}\n  & predicted\\_rank & true\\_rank\\\\\n\\hline\n\t3 & 4220.5 & 1763.5\\\\\n\t6 &  497.0 & 1763.5\\\\\n\t8 & 3621.0 & 1763.5\\\\\n\t9 & 2474.0 & 1763.5\\\\\n\t14 &  979.0 & 1763.5\\\\\n\t15 &  497.0 & 1763.5\\\\\n\t16 & 5800.5 & 5451.0\\\\\n\t17 & 3621.0 & 4257.0\\\\\n\t19 & 1980.0 & 4257.0\\\\\n\t20 & 3031.0 & 1763.5\\\\\n\\end{tabular}\n",
            "text/markdown": "\n| <!--/--> | predicted_rank | true_rank |\n|---|---|---|\n| 3 | 4220.5 | 1763.5 |\n| 6 |  497.0 | 1763.5 |\n| 8 | 3621.0 | 1763.5 |\n| 9 | 2474.0 | 1763.5 |\n| 14 |  979.0 | 1763.5 |\n| 15 |  497.0 | 1763.5 |\n| 16 | 5800.5 | 5451.0 |\n| 17 | 3621.0 | 4257.0 |\n| 19 | 1980.0 | 4257.0 |\n| 20 | 3031.0 | 1763.5 |\n\n",
            "text/html": [
              "<table>\n",
              "<thead><tr><th></th><th scope=col>predicted_rank</th><th scope=col>true_rank</th></tr></thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>3</th><td>4220.5</td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>6</th><td> 497.0</td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>3621.0</td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>9</th><td>2474.0</td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>14</th><td> 979.0</td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>15</th><td> 497.0</td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>5800.5</td><td>5451.0</td></tr>\n",
              "\t<tr><th scope=row>17</th><td>3621.0</td><td>4257.0</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>1980.0</td><td>4257.0</td></tr>\n",
              "\t<tr><th scope=row>20</th><td>3031.0</td><td>1763.5</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "MhshE1OoHDMn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Calculate the absolute differnce of the actual and the predicted rank**"
      ]
    },
    {
      "metadata": {
        "id": "FNSs4qjkFtbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "non_anchor_texts$rank_difference_absolute <- abs(non_anchor_texts$predicted_rank - non_anchor_texts$true_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yCula9G8HKMO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4.Compute the sum of all of the absolute differences between the predicted rank and the actual rank of each review.**"
      ]
    },
    {
      "metadata": {
        "id": "BdDRal5rGUzn",
        "colab_type": "code",
        "outputId": "1e77bc58-62b2-445b-807f-fec3d63d7825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "sum(non_anchor_texts$rank_difference_absolute)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 8789383"
            ],
            "text/latex": "8789383",
            "text/markdown": "8789383",
            "text/html": [
              "8789383"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "TrW9V-64HPkD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Report your findings**\n",
        "\n",
        "The high value of the rank statistic indicates that there is a difference in the rank of the true rank and the predicted rank so the hu & liu approach does not learn the actual sentiment of the reviews."
      ]
    },
    {
      "metadata": {
        "id": "1tRQCdt81FZk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. Next, we’ll train a Naive Bayes classifier to predict if a review is positive or negative.**"
      ]
    },
    {
      "metadata": {
        "id": "XmhQ_RmxxFjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) Use the “textmodel” function in quanteda to train a smoothed Naive Bayes classifier\n",
        "with uniform priors, using 80% of the reviews in the training set and 20% in the test set\n",
        "(Note: features in the test set should match the set of features in the training set. See\n",
        "quanteda’s dfm match function.). Report the accuracy, precision, recall and F1 score of\n",
        "your predictions. Include the confusion matrix in your answer.**"
      ]
    },
    {
      "metadata": {
        "id": "sQpt-iByH0_i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Select the relevant columns from the yelp reviews.**"
      ]
    },
    {
      "metadata": {
        "id": "Dy4t325qI9AJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_reviews_ml <-  yelp_reviews %>% select(text,sentiment) %>% setNames(c(\"text\", \"class\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXof-nOMMFqF",
        "colab_type": "code",
        "outputId": "42d99acd-415d-4473-fa74-ad4bcb38b90d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "dim(yelp_reviews_ml)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 10000     2"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 10000\n\\item 2\n\\end{enumerate*}\n",
            "text/markdown": "1. 10000\n2. 2\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>10000</li>\n",
              "\t<li>2</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gDSYJT1hIQkh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Preprocessing of texts to remove apostrophes**"
      ]
    },
    {
      "metadata": {
        "id": "FPPfT5C8Ml2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# some pre-processing (the rest will let dfm do)\n",
        "yelp_reviews_ml$text <- gsub(pattern = \"'\", \"\", yelp_reviews_ml$text)  # replace apostrophes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iln2MsrbIWsW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Check the proportion of each class in the training data**"
      ]
    },
    {
      "metadata": {
        "id": "3w7kOL-UM-_9",
        "colab_type": "code",
        "outputId": "75f3bd49-b41b-49ef-dcd2-592905e7d968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "prop.table(table(yelp_reviews_ml$class))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Negative Positive \n",
              "  0.6663   0.3337 "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SFHe2V1qIcsr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4. Split into training and test set with 0.8 proportion in the training set and set the seed for reproducing**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SGruGuTGgV_e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set.seed(1984)\n",
        "ids_train <- createDataPartition(1:nrow(news_dfm), p = 0.8, list = FALSE, times = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YsUQxA-HND_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split sample into training & test sets\n",
        "set.seed(1984L)\n",
        "prop_train <- 0.8\n",
        "ids <- 1:nrow(yelp_reviews_ml)\n",
        "ids_train <- sample(ids, ceiling(prop_train*length(ids)), replace = FALSE)\n",
        "ids_test <- ids[-ids_train]\n",
        "train_set <- yelp_reviews_ml[ids_train,]\n",
        "test_set <- yelp_reviews_ml[ids_test,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqGzyOV7IrwH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**5. Create dfms  for the train and test set and remove the extraneous features such as the stopwords and perfrom stemming and remove punctuations**"
      ]
    },
    {
      "metadata": {
        "id": "_HWyzuFMNPLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dfm <- dfm(train_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords(\"english\"))\n",
        "test_dfm <- dfm(test_set$text, stem = TRUE, remove_punct = TRUE, remove = stopwords(\"english\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDRNgDMWNSLL",
        "colab_type": "code",
        "outputId": "fb72858e-2b23-4b82-96ca-8ed7f79c22f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "as.matrix(train_dfm)[1:5,1:5]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       features\n",
              "docs    went halloween night dinner good\n",
              "  text1 1    1         1     1      4   \n",
              "  text2 0    0         0     0      0   \n",
              "  text3 0    0         0     1      1   \n",
              "  text4 0    0         2     0      0   \n",
              "  text5 0    0         0     0      1   "
            ],
            "text/latex": "\\begin{tabular}{r|lllll}\n  & went & halloween & night & dinner & good\\\\\n\\hline\n\ttext1 & 1 & 1 & 1 & 1 & 4\\\\\n\ttext2 & 0 & 0 & 0 & 0 & 0\\\\\n\ttext3 & 0 & 0 & 0 & 1 & 1\\\\\n\ttext4 & 0 & 0 & 2 & 0 & 0\\\\\n\ttext5 & 0 & 0 & 0 & 0 & 1\\\\\n\\end{tabular}\n",
            "text/markdown": "\n| <!--/--> | went | halloween | night | dinner | good |\n|---|---|---|---|---|---|\n| text1 | 1 | 1 | 1 | 1 | 4 |\n| text2 | 0 | 0 | 0 | 0 | 0 |\n| text3 | 0 | 0 | 0 | 1 | 1 |\n| text4 | 0 | 0 | 2 | 0 | 0 |\n| text5 | 0 | 0 | 0 | 0 | 1 |\n\n",
            "text/html": [
              "<table>\n",
              "<thead><tr><th></th><th scope=col>went</th><th scope=col>halloween</th><th scope=col>night</th><th scope=col>dinner</th><th scope=col>good</th></tr></thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>text1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td></tr>\n",
              "\t<tr><th scope=row>text2</th><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>text3</th><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><th scope=row>text4</th><td>0</td><td>0</td><td>2</td><td>0</td><td>0</td></tr>\n",
              "\t<tr><th scope=row>text5</th><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1mIKp_06I7N6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**6. Match features of the test set with the training set.**"
      ]
    },
    {
      "metadata": {
        "id": "qnZoybg3NV6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dfm <- dfm_match(test_dfm, features = featnames(train_dfm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XyFiU6T1JPab",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**7. Train a smoothed Naive Bayes classifier\n",
        "with uniform priors**"
      ]
    },
    {
      "metadata": {
        "id": "nQnAv2-MNYlp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_model_sm <- textmodel_nb(train_dfm, train_set$class, smooth = 1, prior = \"uniform\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G3FcZ-NMNk6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_class_sm <- predict(nb_model_sm, newdata = test_dfm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZCgdGcaNm_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cmat_sm <- table(test_set$class, predicted_class_sm)\n",
        "nb_acc_sm <- sum(diag(cmat_sm))/sum(cmat_sm) # accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "nb_recall_sm <- cmat_sm[2,2]/sum(cmat_sm[2,]) # recall = TP / (TP + FN)\n",
        "nb_precision_sm <- cmat_sm[2,2]/sum(cmat_sm[,2]) # precision = TP / (TP + FP)\n",
        "nb_f1_sm <- 2*(nb_recall_sm*nb_precision_sm)/(nb_recall_sm + nb_precision_sm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1yR018n1NxN8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "baseline_acc <- max(prop.table(table(test_set$class)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2175TVvEJciK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**8. Report the accuracy, precision, recall and F1 score of\n",
        "your predictions. Include the confusion matrix in your answer.**"
      ]
    },
    {
      "metadata": {
        "id": "TbNNWOyubtpI",
        "colab_type": "code",
        "outputId": "75c63212-b1cc-4608-a566-78042e5fe299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "print(cmat_sm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          predicted_class_sm\n",
            "           Negative Positive\n",
            "  Negative     1107      251\n",
            "  Positive      270      372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zrKbGE-ZNo6l",
        "colab_type": "code",
        "outputId": "19103f3e-4118-4f74-d957-badd5f1dead2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "cell_type": "code",
      "source": [
        "cat(\n",
        "  \"Baseline Accuracy: \", baseline_acc, \"\\n\",\n",
        "  \"Accuracy:\",  nb_acc_sm, \"\\n\",\n",
        "  \"Recall:\",  nb_recall_sm, \"\\n\",\n",
        "  \"Precision:\",  nb_precision_sm, \"\\n\",\n",
        "  \"F1-score:\", nb_f1_sm\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy:  0.679 \n",
            " Accuracy: 0.7395 \n",
            " Recall: 0.5794393 \n",
            " Precision: 0.5971108 \n",
            " F1-score: 0.5881423"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_-wz771BNq9U",
        "colab_type": "code",
        "outputId": "24130c61-0c13-4060-bf71-9afd6060bdbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "print(cmat_sm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   predicted_class_sm\n",
            "       0    1\n",
            "  0 1107  251\n",
            "  1  270  372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MN_XPjB1xMgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**b) Were you to change the priors from “uniform” to “docfreq,” would you expect this to\n",
        "change the performance of Naive Bayes predictions? Why? Re-estimate Naive Bayes\n",
        "with the “docfreq” prior and report the accuracy, precision, recall and F1 score of these\n",
        "new results. Include the confusion matrix in your answer. In terms of accuracy, how\n",
        "would you evaluate the performance of this classifier?**"
      ]
    },
    {
      "metadata": {
        "id": "kezyytQyJtzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. change the priors from “uniform” to “docfreq,”**"
      ]
    },
    {
      "metadata": {
        "id": "1dbGRAwJN-7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_model_df <- textmodel_nb(train_dfm, train_set$class, smooth = 1, prior = \"docfreq\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b0AGTEcGOjIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_class_df <- predict(nb_model_df , newdata = test_dfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6wwzudADKC7v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Re-estimate Naive Bayes with the “docfreq” prior and report the accuracy, precision, recall and F1 score of these new results. Include the confusion matrix in your answer**"
      ]
    },
    {
      "metadata": {
        "id": "aE2KlwskKKoj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cmat_df <- table(test_set$class, predicted_class_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NNaphgzoKBL9",
        "colab_type": "code",
        "outputId": "467aaf3e-357d-4a49-f79c-7bd67d419ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "print(cmat_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          predicted_class_df\n",
            "           Negative Positive\n",
            "  Negative     1160      198\n",
            "  Positive      313      329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o5Lx1aE_POtx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cmat_df <- table(test_set$class, predicted_class_df)\n",
        "nb_acc_df<- sum(diag(cmat_df))/sum(cmat_df) # accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "nb_recall_df <- cmat_df[2,2]/sum(cmat_df[2,]) # recall = TP / (TP + FN)\n",
        "nb_precision_df <- cmat_df[2,2]/sum(cmat_sm[,2]) # precision = TP / (TP + FP)\n",
        "nb_f1_df <- 2*(nb_recall_df*nb_precision_df)/(nb_recall_df+ nb_precision_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GgtTEsMSPpmk",
        "colab_type": "code",
        "outputId": "e3d962dc-15e2-4dce-ec2e-1c7c3677a1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "cell_type": "code",
      "source": [
        "cat(\n",
        "  \"Baseline Accuracy: \", baseline_acc, \"\\n\",\n",
        "  \"Accuracy:\",  nb_acc_df, \"\\n\",\n",
        "  \"Recall:\",  nb_recall_df, \"\\n\",\n",
        "  \"Precision:\",  nb_precision_df, \"\\n\",\n",
        "  \"F1-score:\", nb_f1_df\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy:  0.679 \n",
            " Accuracy: 0.7445 \n",
            " Recall: 0.5124611 \n",
            " Precision: 0.5280899 \n",
            " F1-score: 0.5201581"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LYAYSLHCKjNb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**In terms of accuracy, how\n",
        "would you evaluate the performance of this classifier?**\n",
        "\n",
        "The accuracy of the classifier increases from 73% to 74% higher when docfreq priors are used instead of uniform priors. It is slightly better than the uniform priors because uniform priors give equal weightage to the features whereas docfreq , as the name suggests gives the features weightage based ont he docfrequency."
      ]
    },
    {
      "metadata": {
        "id": "Kh1xxZhixaOP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(c) How is accuracy affected if you fit the model without smoothing? Why might this be?**"
      ]
    },
    {
      "metadata": {
        "id": "91uToqdCPuD4",
        "colab_type": "code",
        "outputId": "6d2c70b8-b335-4785-87e3-df517ebb4a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "cell_type": "code",
      "source": [
        "nb_model <- textmodel_nb(train_dfm, train_set$class, smooth = 0, prior = \"uniform\")\n",
        "\n",
        "# evaluate on test set\n",
        "predicted_class <- predict(nb_model, newdata = test_dfm)\n",
        "\n",
        "# baseline\n",
        "baseline_acc <- max(prop.table(table(test_set$class)))\n",
        "\n",
        "# get confusion matrix\n",
        "cmat <- table(test_set$class, predicted_class)\n",
        "nb_acc <- sum(diag(cmat))/sum(cmat) # accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "nb_recall <- cmat[2,2]/sum(cmat[2,]) # recall = TP / (TP + FN)\n",
        "nb_precision <- cmat[2,2]/sum(cmat[,2]) # precision = TP / (TP + FP)\n",
        "nb_f1 <- 2*(nb_recall*nb_precision)/(nb_recall + nb_precision)\n",
        "\n",
        "# print\n",
        "cat(\n",
        "  \"Baseline Accuracy: \", baseline_acc, \"\\n\",\n",
        "  \"Accuracy:\",  nb_acc, \"\\n\",\n",
        "  \"Recall:\",  nb_recall, \"\\n\",\n",
        "  \"Precision:\",  nb_precision, \"\\n\",\n",
        "  \"F1-score:\", nb_f1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy:  0.679 \n",
            " Accuracy: 0.7 \n",
            " Recall: 0.4626168 \n",
            " Precision: 0.5380435 \n",
            " F1-score: 0.4974874"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ol36xD7WLeKi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Discussion:**\n",
        "The performance of the classifier dramatically drops when smoothing is not used. It is less than 50%(random guessing). This is probably because the smoothing fails to account for the unknown words occuring in the test data therefore we get zero overall likelihood and fails to generalize on new words. Thus, resulting poor performance of the classifier."
      ]
    },
    {
      "metadata": {
        "id": "14PzAA5Pxggi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(d) In the above exercise we only used words as features. Can you think of other features\n",
        "beyond words that may help classify the sentiment of a document?**"
      ]
    },
    {
      "metadata": {
        "id": "kBD_DlG0MsMU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "we could employ the use of bi-grams and trigrams. We could also compute sentiments by simply using adverbs and adjectives of the reviews. We could also use the subjectivity and objectivity features of the reviews to classify documents."
      ]
    },
    {
      "metadata": {
        "id": "Y_W0SeAux8Az",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Q6. Now we’ll attempt to do our best on the classification task using a Support Vector Machine\n",
        "(SVM). Since SVM functions are computationally intensive, restrict your analysis to the first\n",
        "1000 reviews using the original ordering of the review data.**"
      ]
    },
    {
      "metadata": {
        "id": "98gJP6BSyMPu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) Describe an advantage offered by SVM or Naive Bayes relative to the dictionary approach\n",
        "or wordscores in classifying positive and negative reviews.**"
      ]
    },
    {
      "metadata": {
        "id": "ejW5val-yPN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Answer 6(a):**\n",
        "But if you want to know the decision boundary then SVM might be a\n",
        "better choice.\n",
        "→ RLR will optimize probabilities of class membership, rather than just\n",
        "trying to learn the boundary (simpler, more direct task).\n",
        "\n",
        "It scales relatively well to high dimensional data.\n",
        "SVM models have generalization in practice, the risk of overfitting is less in SVM.\n",
        "\n",
        "\n",
        "SVM’s are very good when we have no idea on the data.\n",
        "Works well with even unstructured and semi structured data like text, Images and trees.\n",
        "The kernel trick is real strength of SVM. With an appropriate kernel function, we can solve any complex problem.\n",
        "**Reference**\n",
        "https://dzone.com/articles/reasons-to-replace-dictionary-based-text-mining-wi\n",
        "\n",
        "\n",
        "**The Problems With This Approach**\n",
        "The human limitation with manual ontology — It is almost impossible to think of all the relevant keywords and their variants that represent a particular concept. Building and maintaining a manual ontology has a significant impact on the level of accuracy.\n",
        "\n",
        "Lack of domain expertise — When dictionaries are created in one substantive area and then applied to other problems, serious errors can occur. Many words that have a negative connotation in other contexts, like \"higher crude prices,\" may have a positive connotation in the context of the crude company. Also, such approaches fail of phrases like \"fix the broken economy\" or double negatives like \"taste was not bad,\" which frequently occur in every day's conversations.\n",
        "\n",
        "**It's time for a new approach.**\n",
        "\n",
        "Machine Learning enables users to deploy AI to unstructured enterprise content. It is one of the most prominent techniques gaining the interest of researchers due to its adaptability and accuracy. It comprises of four stages: Data collection, Pre-processing, Training data, and Testing and Validating the results. In the training data, a collection of tagged data is provided. A model is created based on the training dataset, which is employed over the new/unseen text for classification purpose. Gather enough opinions — and analyze them correctly — and you've got an accurate gauge of the feelings of the silent majority. This relates not only to how people feel, but the drivers underlying why they feel the way they do.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QvsRm6gmyVS-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(b) Using the “cross validate” command, train an SVM. Your goal is to maximize out of\n",
        "sample accuracy with 5-fold cross-validation. Optimize over the relative size of the training\n",
        "and test sets by training an SVM in 10% intervals from 10% to 90% percent of the\n",
        "data. In other words, you should train 10 different models with 5-fold cross-validation.\n",
        "Report the mean accuracy for each model. Report which model results in the highest\n",
        "average accuracy for out-of-sample predictions made on the test set. In terms of accuracy,\n",
        "how would you evaluate the performance of this classifier?**"
      ]
    },
    {
      "metadata": {
        "id": "OMURl1G0LJFb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "proportions = list(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jz3L7uQoLQMn",
        "colab_type": "code",
        "outputId": "dcbd22ba-6bec-49a6-d1b0-cae223c01a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy <- 0.0\n",
        "baseline_acc <- 0.0\n",
        "model_num <- 1\n",
        "sel_proportion <- 0.0\n",
        "\n",
        "for (proportion in proportions) {\n",
        "\n",
        "\n",
        "  set.seed(1984)\n",
        "  \n",
        "  ids_train <- createDataPartition(1:nrow(yelp_dfm), p = proportion, list = FALSE, times = 1)\n",
        "  train_x <- yelp_dfm[ids_train, ] %>% as.data.frame() # train set data\n",
        "  train_y <- yelp_samp_svn$class[ids_train] %>% as.factor()  # train set labels\n",
        "  test_x <- yelp_dfm[-ids_train, ]  %>% as.data.frame() # test set data\n",
        "  test_y <- yelp_samp_svn$class[-ids_train] %>% as.factor() # test set labels\n",
        "\n",
        "\n",
        "\n",
        "  baseline_acc <- max(prop.table(table(test_y)))\n",
        "  \n",
        "  trctrl <- trainControl(method = \"cv\",n=5)\n",
        "  \n",
        "  \n",
        "  svm_mod_linear <- train(x = train_x,\n",
        "                        y = train_y,\n",
        "                        \n",
        "                        method = \"svmLinear\",\n",
        "                        trControl = trctrl)\n",
        "                        \n",
        "                        \n",
        "  svm_linear_pred <- predict(svm_mod_linear, newdata = test_x)\n",
        "  svm_linear_cmat <- confusionMatrix(svm_linear_pred, test_y)\n",
        "  \n",
        "  if (svm_linear_cmat$overall[[\"Accuracy\"]] > accuracy) {\n",
        "  \n",
        "   accuracy <- svm_linear_cmat$overall[[\"Accuracy\"]]\n",
        "   model_no <- which(proportions == proportion)\n",
        "   sel_proportion <- proportion\n",
        "  }\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "cat( \"\\n\",\n",
        "  \"Model Number\", model_no,\"\\n\",\n",
        "  \"proportion\", sel_proportion,\"\\n\",\n",
        "  \"Baseline Accuracy: \", baseline_acc, \"\\n\",\n",
        "  \"SVM-Linear Accuracy:\",  accuracy, \"\\n\"\n",
        "\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Number 8 \n",
            " proportion 0.8 \n",
            " Baseline Accuracy:  0.69 \n",
            " SVM-Linear Accuracy: 0.715 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XzFpcmCYyq-_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Answer 6(b): Model Number 8 \n",
        " proportion 0.8 \n",
        " Baseline Accuracy:  0.69 \n",
        " SVM-Linear Accuracy: 0.715 **"
      ]
    },
    {
      "metadata": {
        "id": "jC2OXvUwyxuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(c) Take a guess as to which kernel would be best to use in this context, and discuss what\n",
        "assumptions about the data cause you to make that choice. Try both the radial and\n",
        "linear kernels; were you correct?**"
      ]
    },
    {
      "metadata": {
        "id": "l772E19Njz6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "A radial kernel will have a better accuracy than a linear kernel due to high number of features. A linear hyperplane will generalise poorly than a radial hyperplane"
      ]
    },
    {
      "metadata": {
        "id": "CmE0T3d4VffY",
        "colab_type": "code",
        "outputId": "80fb6010-16b7-4ea3-acae-9958476624e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2585
        }
      },
      "cell_type": "code",
      "source": [
        "accuracy <- 0.0\n",
        "baseline_acc <- 0.0\n",
        "model_num <- 1\n",
        "sel_proportion <- 0.0\n",
        "\n",
        "for (proportion in proportions) {\n",
        "\n",
        "\n",
        "  set.seed(1984)\n",
        "  \n",
        "  ids_train <- createDataPartition(1:nrow(yelp_dfm), p = proportion, list = FALSE, times = 1)\n",
        "  train_x <- yelp_dfm[ids_train, ] %>% as.data.frame() # train set data\n",
        "  train_y <- yelp_sample_svm$class[ids_train] %>% as.factor()  # train set labels\n",
        "  test_x <- yelp_dfm[-ids_train, ]  %>% as.data.frame() # test set data\n",
        "  test_y <- yelp_sample_svm$class[-ids_train] %>% as.factor() # test set labels\n",
        "\n",
        "\n",
        "\n",
        "  baseline_acc <- max(prop.table(table(test_y)))\n",
        "  \n",
        "  trctrl <- trainControl(method = \"cv\",n=5)\n",
        "  \n",
        "  \n",
        "  svm_mod_linear <- train(x = train_x,\n",
        "                        y = train_y,\n",
        "                        \n",
        "                        method = \"svmRadial\",\n",
        "                        trControl = trctrl)\n",
        "                        \n",
        "                        \n",
        "  svm_linear_pred <- predict(svm_mod_linear, newdata = test_x)\n",
        "  svm_linear_cmat <- confusionMatrix(svm_linear_pred, test_y)\n",
        "  \n",
        "  if (svm_linear_cmat$overall[[\"Accuracy\"]] > accuracy) {\n",
        "  \n",
        "   accuracy <- svm_linear_cmat$overall[[\"Accuracy\"]]\n",
        "   model_no <- which(proportions == proportion)\n",
        "   sel_proportion <- proportion\n",
        "  }\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "cat( \"\\n\",\n",
        "  \"Model Number\", model_no,\"\\n\",\n",
        "  \"proportion\", sel_proportion,\"\\n\",\n",
        "  \"Baseline Accuracy: \", baseline_acc, \"\\n\",\n",
        "  \"SVM-Radial Accuracy:\",  accuracy, \"\\n\"\n",
        "\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”Warning message in .local(x, ...):\n",
            "“Variable(s) `' constant. Cannot scale data.”"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Model Number 9 \n",
            " proportion 0.9 \n",
            " Baseline Accuracy:  0.69 \n",
            " SVM-Radial Accuracy: 0.74 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i9_5XXtpy25w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Answer 6(c): Model Number 9 \n",
        " proportion 0.9 \n",
        " Baseline Accuracy:  0.69 \n",
        " SVM-Radial Accuracy: 0.74 **"
      ]
    },
    {
      "metadata": {
        "id": "cMoJby3O1xh0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q5. Although there isn’t really an “ideology” in this example, there is an underlying positivenegative\n",
        "latent space that we can use to train a “wordscores model.” In this question, you\n",
        "will be implementing “wordscores” by hand. You may use functions in base R and quanteda,\n",
        "but not the built-in “wordscores” function.**"
      ]
    },
    {
      "metadata": {
        "id": "kD4Q2amu17nA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) Create a vector of “wordscores” for the words that appear in the “anchor negative” and\n",
        "“anchor positive” reviews (from question 2b) using the technique described in Laver,\n",
        "Benoit & Garry (2003). That is, you should fit a “wordscores” model to the anchor\n",
        "texts. What are the most extreme words (i.e. words with the lowest and highest wordscores)?\n",
        "Report your findings.**"
      ]
    },
    {
      "metadata": {
        "id": "xj4q77umIaXl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Collapse all the positive anchor reviews into 1 value for positive anchor and negatie anchor reviews separately**"
      ]
    },
    {
      "metadata": {
        "id": "OLH5udGtJPMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "anchor_positive_text <- paste(unlist(yelp_reviews$text[yelp_reviews$anchor ==\"Positive\"]), collapse =\" \")\n",
        "anchor_negative_text <- paste(unlist(yelp_reviews$text[yelp_reviews$anchor ==\"Negative\"]), collapse =\" \")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QySAkvraImhO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Create a dfm for theses two positive negative corpuses as documents**"
      ]
    },
    {
      "metadata": {
        "id": "9GJr8CMS5HKY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "anchor_texts_dfm <- dfm(c(anchor_positive_text, anchor_negative_text), stem = TRUE, remove_punct = TRUE, remove = stopwords(\"english\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSS3XdhBX6pA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "anchor_texts_train_features <- featnames(anchor_texts_dfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Htdcw8-vkDe2",
        "colab_type": "code",
        "outputId": "a0934013-e981-4075-bf61-6f6b3f541fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "length(anchor_texts_train_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 14681"
            ],
            "text/latex": "14681",
            "text/markdown": "14681",
            "text/html": [
              "14681"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gsdd2ZZ8IuHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Normalize the frequency of the word in each document by the total number of words occuring in each document by their rowsum**"
      ]
    },
    {
      "metadata": {
        "id": "6TRgMaSvzEsA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "anchor_texts_dfm <- anchor_texts_dfm / rowSums(anchor_texts_dfm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SfZ_RC9RiNpW",
        "colab_type": "code",
        "outputId": "ec57eea8-84d0-478a-ec30-aecd80600922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "sort(anchor_texts_dfm[2,])[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "semi-busi    griddl  sweetish        42      rosi    dakota   chaparr      path \n",
              "        0         0         0         0         0         0         0         0 \n",
              " xeriscap  ballpark \n",
              "        0         0 "
            ],
            "text/latex": "\\begin{description*}\n\\item[semi-busi] 0\n\\item[griddl] 0\n\\item[sweetish] 0\n\\item[42] 0\n\\item[rosi] 0\n\\item[dakota] 0\n\\item[chaparr] 0\n\\item[path] 0\n\\item[xeriscap] 0\n\\item[ballpark] 0\n\\end{description*}\n",
            "text/markdown": "semi-busi\n:   0griddl\n:   0sweetish\n:   042\n:   0rosi\n:   0dakota\n:   0chaparr\n:   0path\n:   0xeriscap\n:   0ballpark\n:   0\n\n",
            "text/html": [
              "<dl class=dl-horizontal>\n",
              "\t<dt>semi-busi</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>griddl</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>sweetish</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>42</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>rosi</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>dakota</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>chaparr</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>path</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>xeriscap</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>ballpark</dt>\n",
              "\t\t<dd>0</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UUPVBWS32C_U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(b) Apply your wordscores model to the non-anchor documents. This should generate a\n",
        "wordscores estimate for each document. Calculate the RankSum statistic (described in\n",
        "Equation 1) of the reviews as scored by wordscores in the same way as you did for the\n",
        "dictionaries. Report your findings. By this metric, which did better: dictionaries or\n",
        "wordscores?**"
      ]
    },
    {
      "metadata": {
        "id": "mRINMe98QE6o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**4.Divide the relative frequency of the word in each document by the sum of relative frequency occuring in the positive and negative document by taking the colsums**"
      ]
    },
    {
      "metadata": {
        "id": "aD3vWZL2fWs6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "colSums_anchor <- colSums(anchor_texts_dfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HgGoOjQ8_nG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### calculate word score\n",
        "\n",
        "\n",
        "anchor_texts_dfm[1,] <- anchor_texts_dfm[1,] / colSums_anchor\n",
        "anchor_texts_dfm[2,] <- anchor_texts_dfm[2,] / colSums_anchor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pc9qj57YKIw6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**5.Subtact :-> . (positive normalized-frequency  - negative normalized-frequency) for each word in dfm for the two documents**"
      ]
    },
    {
      "metadata": {
        "id": "t1_yOXH7AcnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "overall_word_score <- anchor_texts_dfm[1,] - anchor_texts_dfm[2,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fq0-hYQlQnvc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**QUESTION: What are the most extreme words (i.e. words with the lowest and highest wordscores (training data)) ??**"
      ]
    },
    {
      "metadata": {
        "id": "juQlxZWfAjjn",
        "colab_type": "code",
        "outputId": "f81384f8-79cd-4c53-a58b-14738790d546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "cell_type": "code",
      "source": [
        "sort(overall_word_score,decreasing=TRUE)[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "semi-busi    griddl  sweetish        42      rosi    dakota   chaparr      path \n",
              "        1         1         1         1         1         1         1         1 \n",
              " xeriscap  ballpark \n",
              "        1         1 "
            ],
            "text/latex": "\\begin{description*}\n\\item[semi-busi] 1\n\\item[griddl] 1\n\\item[sweetish] 1\n\\item[42] 1\n\\item[rosi] 1\n\\item[dakota] 1\n\\item[chaparr] 1\n\\item[path] 1\n\\item[xeriscap] 1\n\\item[ballpark] 1\n\\end{description*}\n",
            "text/markdown": "semi-busi\n:   1griddl\n:   1sweetish\n:   142\n:   1rosi\n:   1dakota\n:   1chaparr\n:   1path\n:   1xeriscap\n:   1ballpark\n:   1\n\n",
            "text/html": [
              "<dl class=dl-horizontal>\n",
              "\t<dt>semi-busi</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>griddl</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>sweetish</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>42</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>rosi</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>dakota</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>chaparr</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>path</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>xeriscap</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>ballpark</dt>\n",
              "\t\t<dd>1</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FeG0KUjJfOig",
        "colab_type": "code",
        "outputId": "dbfa3032-e21a-4b89-c82e-33a903ecbed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "cell_type": "code",
      "source": [
        "sort(overall_word_score)[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     brake      gaudi    soprano        1-1 pittsburgh     gristl     pinkey \n",
              "        -1         -1         -1         -1         -1         -1         -1 \n",
              "burlington     hmmmmm    hmmmmmm \n",
              "        -1         -1         -1 "
            ],
            "text/latex": "\\begin{description*}\n\\item[brake] -1\n\\item[gaudi] -1\n\\item[soprano] -1\n\\item[1-1] -1\n\\item[pittsburgh] -1\n\\item[gristl] -1\n\\item[pinkey] -1\n\\item[burlington] -1\n\\item[hmmmmm] -1\n\\item[hmmmmmm] -1\n\\end{description*}\n",
            "text/markdown": "brake\n:   -1gaudi\n:   -1soprano\n:   -11-1\n:   -1pittsburgh\n:   -1gristl\n:   -1pinkey\n:   -1burlington\n:   -1hmmmmm\n:   -1hmmmmmm\n:   -1\n\n",
            "text/html": [
              "<dl class=dl-horizontal>\n",
              "\t<dt>brake</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>gaudi</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>soprano</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>1-1</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>pittsburgh</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>gristl</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>pinkey</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>burlington</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>hmmmmm</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>hmmmmmm</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "</dl>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "T8vroyj_K3XC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**6. lets start work with the neutral anchor documents:**"
      ]
    },
    {
      "metadata": {
        "id": "oxQM_q15AyGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#### \n",
        "\n",
        "neutral_anchor_docs <- yelp_reviews[yelp_reviews$anchor ==\"Neutral\",]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_G87BNRT8cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neutral_anchor_docs$text <- as.character(neutral_anchor_docs$text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Vn4kTx8Cu35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neutral_terms_dfm <- dfm(neutral_anchor_docs$text, stem=TRUE, remove_punct = TRUE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntTH3SyRQ_5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Match features of virigin texts to that of the trainingtest set. We dont factor in the words which are outside the training set**"
      ]
    },
    {
      "metadata": {
        "id": "jlwQnOwjuMwD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neutral_terms_dfm <- dfm_match(neutral_terms_dfm,features=c(featnames(dfm_overall)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CNmlNiOlLM7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**7. Normalize the frequency of the words by the total number of words in the document by calculating the rowsum**"
      ]
    },
    {
      "metadata": {
        "id": "9D4zvZWQZ1wx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rowsum_neutrall_docs <- neutral_terms_dfm / rowSums(neutral_terms_dfm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y0hLr3c3uy3H",
        "colab_type": "code",
        "outputId": "d1d3d2b4-f23a-48b6-bdef-ca82897f9404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "cell_type": "code",
      "source": [
        "dim(rowsum_neutrall_docs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1]  5914 14681"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 5914\n\\item 14681\n\\end{enumerate*}\n",
            "text/markdown": "1. 5914\n2. 14681\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>5914</li>\n",
              "\t<li>14681</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "v1YdrtGxwaNj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "virgin_text_scores <- rowsum_neutrall_docs %*% t(dfm_overall)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vpv0pVu8LsTO",
        "colab_type": "code",
        "outputId": "2c530c3b-4d0d-453d-b226-4c88dae41175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "virgin_text_scores[1:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " [1]  0.407053380  0.131762460  0.008163444  0.118468339  0.092864713\n",
              " [6]  0.145793422 -0.027855650  0.030980344  0.093893931 -0.043247304"
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 0.407053380049565\n\\item 0.131762459580811\n\\item 0.00816344362584322\n\\item 0.118468338600887\n\\item 0.0928647127476559\n\\item 0.145793421790187\n\\item -0.0278556499150349\n\\item 0.0309803443565254\n\\item 0.0938939309917735\n\\item -0.0432473036718729\n\\end{enumerate*}\n",
            "text/markdown": "1. 0.407053380049565\n2. 0.131762459580811\n3. 0.00816344362584322\n4. 0.118468338600887\n5. 0.0928647127476559\n6. 0.145793421790187\n7. -0.0278556499150349\n8. 0.0309803443565254\n9. 0.0938939309917735\n10. -0.0432473036718729\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>0.407053380049565</li>\n",
              "\t<li>0.131762459580811</li>\n",
              "\t<li>0.00816344362584322</li>\n",
              "\t<li>0.118468338600887</li>\n",
              "\t<li>0.0928647127476559</li>\n",
              "\t<li>0.145793421790187</li>\n",
              "\t<li>-0.0278556499150349</li>\n",
              "\t<li>0.0309803443565254</li>\n",
              "\t<li>0.0938939309917735</li>\n",
              "\t<li>-0.0432473036718729</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "L-GtvxN5Ly9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neutral_anchor_docs$wordscore_sentiment <- virgin_text_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Adtv1TfXMDu3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**8. Calculate the rank statistic on the virgin text similar to that for th hu&Liu approach                                             **"
      ]
    },
    {
      "metadata": {
        "id": "etHqAAEgMl9G",
        "colab_type": "code",
        "outputId": "8c7417e2-b2c9-4f7e-c238-45df49190a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "cell_type": "code",
      "source": [
        "neutral_anchor_docs$predicted_rank <- rank(-neutral_anchor_docs$wordscore_sentiment)\n",
        "neutral_anchor_docs$true_rank <- rank(-neutral_anchor_docs$stars)\n",
        "neutral_anchor_docs %>% select(predicted_rank, true_rank) %>% head(10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sparse>[ <logic> ] : .M.sub.i.logical() maybe inefficient\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   predicted_rank true_rank\n",
              "3    56           1763.5   \n",
              "6  2550           1763.5   \n",
              "8  5199           1763.5   \n",
              "9  2884           1763.5   \n",
              "14 3598           1763.5   \n",
              "15 2207           1763.5   \n",
              "16 5553           5451.0   \n",
              "17 4886           4257.0   \n",
              "19 3569           4257.0   \n",
              "20 5635           1763.5   "
            ],
            "text/latex": "\\begin{tabular}{r|ll}\n  & predicted\\_rank & true\\_rank\\\\\n\\hline\n\t3 &   56   & 1763.5\\\\\n\t6 & 2550   & 1763.5\\\\\n\t8 & 5199   & 1763.5\\\\\n\t9 & 2884   & 1763.5\\\\\n\t14 & 3598   & 1763.5\\\\\n\t15 & 2207   & 1763.5\\\\\n\t16 & 5553   & 5451.0\\\\\n\t17 & 4886   & 4257.0\\\\\n\t19 & 3569   & 4257.0\\\\\n\t20 & 5635   & 1763.5\\\\\n\\end{tabular}\n",
            "text/markdown": "\n| <!--/--> | predicted_rank | true_rank |\n|---|---|---|\n| 3 |   56   | 1763.5 |\n| 6 | 2550   | 1763.5 |\n| 8 | 5199   | 1763.5 |\n| 9 | 2884   | 1763.5 |\n| 14 | 3598   | 1763.5 |\n| 15 | 2207   | 1763.5 |\n| 16 | 5553   | 5451.0 |\n| 17 | 4886   | 4257.0 |\n| 19 | 3569   | 4257.0 |\n| 20 | 5635   | 1763.5 |\n\n",
            "text/html": [
              "<table>\n",
              "<thead><tr><th></th><th scope=col>predicted_rank</th><th scope=col>true_rank</th></tr></thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>3</th><td>  56  </td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>2550  </td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>8</th><td>5199  </td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>9</th><td>2884  </td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>14</th><td>3598  </td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>15</th><td>2207  </td><td>1763.5</td></tr>\n",
              "\t<tr><th scope=row>16</th><td>5553  </td><td>5451.0</td></tr>\n",
              "\t<tr><th scope=row>17</th><td>4886  </td><td>4257.0</td></tr>\n",
              "\t<tr><th scope=row>19</th><td>3569  </td><td>4257.0</td></tr>\n",
              "\t<tr><th scope=row>20</th><td>5635  </td><td>1763.5</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Qezqw52XNZBs",
        "colab_type": "code",
        "outputId": "caeb4737-463e-41e0-d0f8-c748a3bfc650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "neutral_anchor_docs$rank_difference_absolute <- abs(neutral_anchor_docs$predicted_rank - neutral_anchor_docs$true_rank)\n",
        "sum(neutral_anchor_docs$rank_difference_absolute)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] 8140582"
            ],
            "text/latex": "8140582",
            "text/markdown": "8140582",
            "text/html": [
              "8140582"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3bhuOrP1N59g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Discussion**\n",
        "Wordscores model performs slightly better if not worse than the hu-liu dictionary scoring method.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ZsoqRNNHzx2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Q7: Finally, let’s try out a Random forest classifier. For this question use the first 500 reviews in\n",
        "the dataset.\n",
        "**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ui8y_rFUzsPa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set.seed(1984)\n",
        "yelp_samp <- yelp_reviews_ml %>% \n",
        "  sample_n(500) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "a41c6e44-8823-4657-d762-741b6ffea9b8",
        "id": "GSYtzSd_zre6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "prop.table(table(yelp_samp$class))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "    0     1 \n",
              "0.657 0.343 "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RgCd_gKWltV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set.seed(1984)\n",
        "yelp_samp <- yelp_samp %>% sample_n(nrow(yelp_samp))\n",
        "rownames(yelp_samp) <- NULL\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLMYOC1tl1Ud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "yelp_dfm <- dfm(yelp_samp$text, stem = TRUE, remove_punct = TRUE, remove = stopwords(\"english\")) %>% convert(\"matrix\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uQeunlJ_l6sO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "presen_absent <- yelp_dfm \n",
        "presen_absent[presen_absent > 0] <- 1\n",
        "feature_count <- apply(presen_absent, 2, sum)\n",
        "features <- names(which(feature_count > 5))\n",
        "yelp_dfm <- yelp_dfm[,features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5kW0p-Tbz7CK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(a) As we did for the Naive Bayes model, split the dataset into a training (80%) and a test\n",
        "set (20%) and construct a document feature matrix for each (Note: features in the test\n",
        "set should match the set of features in the training set).**"
      ]
    },
    {
      "metadata": {
        "id": "X3SXEYivmCcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set.seed(1984)\n",
        "ids_train <- createDataPartition(1:nrow(yelp_dfm), p = 0.8, list = FALSE, times = 1)\n",
        "train_x <- yelp_dfm[ids_train, ] %>% as.data.frame() # train set data\n",
        "train_y <- yelp_samp$class[ids_train] %>% as.factor()  # train set labels\n",
        "test_x <- yelp_dfm[-ids_train, ]  %>% as.data.frame() # test set data\n",
        "test_y <- yelp_samp$class[-ids_train] %>% as.factor() # test set labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_K220DfmV-l",
        "colab_type": "code",
        "outputId": "7f063eaf-dc77-4d45-cbef-6a1ecbb788b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "mtry = sqrt(ncol(train_x))  # number of features to sample at each split\n",
        "ntree = 51  # numbre of trees to grow\n",
        "# more trees generally improve accuracy but at the cost of computation time\n",
        "# odd numbers avoid ties (recall default aggregation is \"majority voting\")\n",
        "set.seed(1984)\n",
        "system.time(rf.base <- randomForest(x = train_x, y = train_y))\n",
        "token_importance <- round(importance(rf.base, 2), 2)\n",
        "# print results\n",
        "print(rf.base)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   user  system elapsed \n",
              " 74.824   0.001  74.845 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[1] \"great\" \"best\"  \"amaz\"  \"love\"  \"good\"  \"excel\""
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'great'\n\\item 'best'\n\\item 'amaz'\n\\item 'love'\n\\item 'good'\n\\item 'excel'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'great'\n2. 'best'\n3. 'amaz'\n4. 'love'\n5. 'good'\n6. 'excel'\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>'great'</li>\n",
              "\t<li>'best'</li>\n",
              "\t<li>'amaz'</li>\n",
              "\t<li>'love'</li>\n",
              "\t<li>'good'</li>\n",
              "\t<li>'excel'</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Call:\n",
            " randomForest(x = train_x, y = train_y) \n",
            "               Type of random forest: classification\n",
            "                     Number of trees: 500\n",
            "No. of variables tried at each split: 39\n",
            "\n",
            "        OOB estimate of  error rate: 30.75%\n",
            "Confusion matrix:\n",
            "    0  1 class.error\n",
            "0 476 46  0.08812261\n",
            "1 200 78  0.71942446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DVaX43RSpwgW",
        "colab_type": "code",
        "outputId": "5002a56f-539b-47a3-a740-fb0312b6fa50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "cell_type": "code",
      "source": [
        "print(rf.base)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Call:\n",
            " randomForest(x = train_x, y = train_y) \n",
            "               Type of random forest: classification\n",
            "                     Number of trees: 500\n",
            "No. of variables tried at each split: 39\n",
            "\n",
            "        OOB estimate of  error rate: 30.75%\n",
            "Confusion matrix:\n",
            "    0  1 class.error\n",
            "0 476 46  0.08812261\n",
            "1 200 78  0.71942446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bjW7lSZ50DHw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(b) Using the randomForest package fit a random forest model to the training set using\n",
        "the package’s default values for ntree and mtry (also, set the importance argument to\n",
        "TRUE). Having fitted the model, extract the mean decrease in Gini importance for the\n",
        "feature set and order from most important to least important. What are the top 10\n",
        "most important features according to this measure?**"
      ]
    },
    {
      "metadata": {
        "id": "6MNd7e3AplU9",
        "colab_type": "code",
        "outputId": "dbfb2987-5ece-4978-ce18-26c8eac17c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "head(rownames(token_importance)[order(-token_importance)],10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " [1] \"amaz\"   \"best\"   \"great\"  \"love\"   \"good\"   \"pretti\" \"ever\"   \"delici\"\n",
              " [9] \"worth\"  \"time\"  "
            ],
            "text/latex": "\\begin{enumerate*}\n\\item 'amaz'\n\\item 'best'\n\\item 'great'\n\\item 'love'\n\\item 'good'\n\\item 'pretti'\n\\item 'ever'\n\\item 'delici'\n\\item 'worth'\n\\item 'time'\n\\end{enumerate*}\n",
            "text/markdown": "1. 'amaz'\n2. 'best'\n3. 'great'\n4. 'love'\n5. 'good'\n6. 'pretti'\n7. 'ever'\n8. 'delici'\n9. 'worth'\n10. 'time'\n\n\n",
            "text/html": [
              "<ol class=list-inline>\n",
              "\t<li>'amaz'</li>\n",
              "\t<li>'best'</li>\n",
              "\t<li>'great'</li>\n",
              "\t<li>'love'</li>\n",
              "\t<li>'good'</li>\n",
              "\t<li>'pretti'</li>\n",
              "\t<li>'ever'</li>\n",
              "\t<li>'delici'</li>\n",
              "\t<li>'worth'</li>\n",
              "\t<li>'time'</li>\n",
              "</ol>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LDJjtTXYpmtZ",
        "colab_type": "code",
        "outputId": "38ac780f-cf3e-4d4a-c271-4c8083242c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "cell_type": "code",
      "source": [
        "varImpPlot(rf.base, n.var = 10, main = \"Variable Importance\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nQmCC",
            "text/plain": [
              "Plot with title “Variable Importance”"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oDiKdEkHqgJo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rf.base <- randomForest(x = train_x, y = train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fNl0Ac6qGKB",
        "colab_type": "code",
        "outputId": "d56a1f2d-c11c-4e63-9756-091a66e4652d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "cell_type": "code",
      "source": [
        "confusionMatrix(predict(rf.base, newdata = test_x), test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "          Reference\n",
              "Prediction Negative Positive\n",
              "  Negative       57       26\n",
              "  Positive       10        7\n",
              "                                          \n",
              "               Accuracy : 0.64            \n",
              "                 95% CI : (0.5379, 0.7336)\n",
              "    No Information Rate : 0.67            \n",
              "    P-Value [Acc > NIR] : 0.77323         \n",
              "                                          \n",
              "                  Kappa : 0.0717          \n",
              "                                          \n",
              " Mcnemar's Test P-Value : 0.01242         \n",
              "                                          \n",
              "            Sensitivity : 0.8507          \n",
              "            Specificity : 0.2121          \n",
              "         Pos Pred Value : 0.6867          \n",
              "         Neg Pred Value : 0.4118          \n",
              "             Prevalence : 0.6700          \n",
              "         Detection Rate : 0.5700          \n",
              "   Detection Prevalence : 0.8300          \n",
              "      Balanced Accuracy : 0.5314          \n",
              "                                          \n",
              "       'Positive' Class : Negative        \n",
              "                                          "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hRX0BUdL0I8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(c) Using the fitted model, predict the sentiment values for the test set and report the confusion\n",
        "matrix along with accuracy, precision, recall and F1 score.**"
      ]
    },
    {
      "metadata": {
        "id": "vR039ldwsa_N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_class_rf <- predict(rf.base, newdata = test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKtxXGY_rK7K",
        "colab_type": "code",
        "outputId": "a471df93-cfd4-4016-8c21-fdeb048fbbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "cell_type": "code",
      "source": [
        "cmat <- table(test_y, predicted_class_rf)\n",
        "nb_acc <- sum(diag(cmat))/sum(cmat) # accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
        "nb_recall <- cmat[2,2]/sum(cmat[2,]) # recall = TP / (TP + FN)\n",
        "nb_precision <- cmat[2,2]/sum(cmat[,2]) # precision = TP / (TP + FP)\n",
        "nb_f1 <- 2*(nb_recall*nb_precision)/(nb_recall + nb_precision)\n",
        "\n",
        "# print\n",
        "cat(\n",
        "  \n",
        "  \"Accuracy:\",  nb_acc, \"\\n\",\n",
        "  \"Recall:\",  nb_recall, \"\\n\",\n",
        "  \"Precision:\",  nb_precision, \"\\n\",\n",
        "  \"F1-score:\", nb_f1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.64 \n",
            " Recall: 0.2121212 \n",
            " Precision: 0.4117647 \n",
            " F1-score: 0.28"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Y2NfbdP0M5X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(d) Now you will do some tuning of one the two model parameters. The package’s default\n",
        "value for the argument mtry is sqrt(#offeatures). Estimate two more models,\n",
        "one for each of two different values of mtry: 0.5 ∗ sqrt(#offeatures) and 1.5 ∗\n",
        "sqrt(#offeatures). As you did above, use each of the fitted models to predict the sentiment\n",
        "values for the test set and report the respective accuracy scores. Which value of\n",
        "mtry yielded the best accuracy?**"
      ]
    },
    {
      "metadata": {
        "id": "PIGnVzUEsylT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Parameter tuning: Question 7/d:\n",
        "\n",
        "trainControl <- trainControl(method = \"cv\", number = 5)\n",
        "metric <- \"Accuracy\"\n",
        "tunegrid <- expand.grid(.mtry = c(0.5*mtry, 1.5*mtry))  # at the moment caret only allows tuning of mtry (partly b/c ntree is just a matter of computational constratints)\n",
        "set.seed(1984)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e37n7xe9uKBI",
        "colab_type": "code",
        "outputId": "d4136715-3426-4fb8-bd0f-0d9ec5ed804c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "system.time(rf.grid <- train(x = train_x, y = train_y, method = \"rf\", metric = metric, tuneGrid = tunegrid, trControl = trainControl, \n",
        "                             ntree = ntree))\n",
        "# print grid search results\n",
        "print(rf.grid)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   user  system elapsed \n",
              " 12.514   0.007  12.527 "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Random Forest \n",
            "\n",
            "400 samples\n",
            "911 predictors\n",
            "  2 classes: 'Negative', 'Positive' \n",
            "\n",
            "No pre-processing\n",
            "Resampling: Cross-Validated (5 fold) \n",
            "Summary of sample sizes: 321, 319, 320, 320, 320 \n",
            "Resampling results across tuning parameters:\n",
            "\n",
            "  mtry      Accuracy   Kappa    \n",
            "  15.09139  0.6826016  0.1831115\n",
            "  45.27416  0.6773832  0.2389227\n",
            "\n",
            "Accuracy was used to select the optimal model using the largest value.\n",
            "The final value used for the model was mtry = 15.09139.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}